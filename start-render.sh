#!/bin/bash

echo "ğŸš€ CIVICOS SUITE - RENDER STARTUP SCRIPT"
echo "========================================="

# Set production environment
export NODE_ENV=production
export RENDER=true

# Install Ollama if not already installed
if ! command -v ollama &> /dev/null; then
    echo "ğŸ¤– Installing Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
fi

# Start Ollama service in background
echo "ğŸ¤– Starting Ollama AI service..."
ollama serve > /dev/null 2>&1 &

# Wait for Ollama to be ready
echo "â³ Waiting for Ollama to be ready..."
sleep 10

# Pull the Mistral model if not already available
echo "ğŸ“¥ Ensuring Mistral model is available..."
ollama pull mistral:latest

# Verify Ollama is running
echo "ğŸ” Verifying Ollama service..."
if curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "âœ… Ollama is running successfully"
    echo "ğŸ“‹ Available models:"
    ollama list
else
    echo "âš ï¸  Ollama may not be ready, continuing anyway..."
fi

# Start the main application
echo "ğŸš€ Starting CivicOS application on Render..."
echo "ğŸŒ Frontend: https://civicos.onrender.com"
echo "ğŸ”§ Backend: https://civicos.onrender.com/api"
echo "ğŸ¤– AI Service: https://civicos.onrender.com/api/ai"

# Start the Node.js application
NODE_ENV=production RENDER=true node dist/server/index.js 