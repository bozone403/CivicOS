#!/bin/bash

echo "ğŸš€ Starting CivicOS with Ollama and Mistral..."

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "ğŸ“¦ Installing Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
fi

# Start Ollama in background with proper configuration
echo "ğŸ¤– Starting Ollama service..."
OLLAMA_HOST=0.0.0.0:11434 ollama serve &
OLLAMA_PID=$!

# Wait for Ollama to be ready
echo "â³ Waiting for Ollama to be ready..."
sleep 10

# Check if Mistral model is available
echo "ğŸ” Checking for Mistral model..."
if ! ollama list | grep -q "mistral"; then
    echo "ğŸ“¥ Downloading Mistral model..."
    ollama pull mistral:latest
else
    echo "âœ… Mistral model already available"
fi

# Test Ollama connection
echo "ğŸ§ª Testing Ollama connection..."
if curl -s http://127.0.0.1:11434/api/tags > /dev/null; then
    echo "âœ… Ollama is running and ready"
else
    echo "âŒ Ollama is not responding"
    exit 1
fi

# Start the Node.js application
echo "ğŸŒ Starting CivicOS application..."
exec node dist/server/index.js 